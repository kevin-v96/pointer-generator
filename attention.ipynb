{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYoIaaQHTCaT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.8.1)\n",
      "Requirement already satisfied: contractions in /opt/conda/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/conda/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /opt/conda/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install contractions\n",
    "import contractions\n",
    "import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from gensim.models import FastText\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbowAMISDjHJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287113"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../misc/cnn_dailymail/train.csv')\n",
    "val_data = pd.read_csv('../misc/cnn_dailymail/validation.csv')\n",
    "test_data = pd.read_csv('../misc/cnn_dailymail/test.csv')\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7lqLjyLLDXa"
   },
   "outputs": [],
   "source": [
    "x = train_data['article']\n",
    "y = train_data['highlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BlfwPHtNXI9"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = contractions.fix(text)\n",
    "    text = html.unescape(text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z0-9]',' ',text) \n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "969v-EnfDlun"
   },
   "outputs": [],
   "source": [
    "cleaned_source = list(map(clean,x))\n",
    "cleaned_summary = list(map(clean,y))\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "for i in range(len(cleaned_summary)):\n",
    "    cleaned_summary[i] = START_TOKEN + \" \" + cleaned_summary[i] + \" \" + END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bgI2vw5DsYw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24409\n",
      "24409\n"
     ]
    }
   ],
   "source": [
    "new_source = []\n",
    "new_summary = []\n",
    "\n",
    "max_source_length = 300\n",
    "max_summary_length = 100\n",
    "\n",
    "for i in range(len(cleaned_source)):\n",
    "    if len(cleaned_source[i].split()) <= max_source_length and len(cleaned_summary[i].split()) <= max_summary_length :\n",
    "        new_source.append(cleaned_source[i])\n",
    "        new_summary.append(cleaned_summary[i])\n",
    "\n",
    "print(len(new_source))\n",
    "print(len(new_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir5TQ3vGZxNe"
   },
   "outputs": [],
   "source": [
    "#from gensim.models import FastText\n",
    "\n",
    "#sentences = new_source + new_summary\n",
    "#sent_ted = [] #all the words\n",
    "#for sent in sentences:\n",
    "#    sent_ted_child = sent.split()\n",
    "#    sent_ted.append(sent_ted_child)\n",
    "\n",
    "#print(sent_ted[0])\n",
    "\n",
    "#model_ted = FastText(sent_ted, vector_size=128, window=3, min_count=1, workers=4,sg=1, epochs=1500)\n",
    "\n",
    "#import pickle\n",
    "#pickle.dump(model_ted, open('128_emb_inshorts.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYIUn8RXDX15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dairy', 0.6152066588401794), ('breast', 0.554631233215332), ('food', 0.5541932582855225), ('lactose', 0.5267015695571899), ('mooo', 0.5247284770011902), ('alcoholic', 0.5210902690887451), ('70g', 0.5209250450134277), ('cream', 0.5195273160934448), ('gallons', 0.5182810425758362), ('aizu', 0.5173525214195251)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_ted = pickle.load(open('./128_emb_cnn_300_100.pkl', 'rb'))\n",
    "weights = model_ted.wv #weight vectors representing all the words\n",
    "print(model_ted.wv.most_similar(\"milk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otf9wqD83OxL"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "word2Index_enc = {} #encoder word-2-index\n",
    "word2Index_dec = {} #decoder word-2-index\n",
    "\n",
    "ind2Word_enc = {} #reverse dictionaries for the above\n",
    "ind2Word_dec = {}\n",
    "\n",
    "encoder_paragraph = list(set((' '.join(new_source)).split()))\n",
    "\n",
    "decoder_paragraph_list = list((' '.join(new_summary)).split())\n",
    "decoder_dict = OrderedDict()\n",
    "\n",
    "for word in decoder_paragraph_list: #make a freq_dict of decoder words\n",
    "    try:\n",
    "        decoder_dict[word] = decoder_dict[word] + 1\n",
    "    except:\n",
    "        decoder_dict[word] = 1\n",
    "\n",
    "ind2Word_enc[0] = START_TOKEN\n",
    "ind2Word_dec[0] = START_TOKEN\n",
    "word2Index_enc[START_TOKEN] = 0\n",
    "word2Index_dec[START_TOKEN] = 0\n",
    "ind2Word_enc[1] = END_TOKEN\n",
    "ind2Word_dec[1] = END_TOKEN\n",
    "word2Index_enc[END_TOKEN] = 1\n",
    "word2Index_dec[END_TOKEN] = 1\n",
    "\n",
    "dec_index = 1\n",
    "for (decoder_dict_word, decoder_dict_number) in decoder_dict.items():\n",
    "    word2Index_dec[decoder_dict_word] = dec_index\n",
    "    ind2Word_dec[dec_index] = decoder_dict_word\n",
    "    dec_index+=1\n",
    "\n",
    "enc_index = 1\n",
    "for index,word in enumerate(encoder_paragraph):\n",
    "    if word != ' ':\n",
    "        word2Index_enc[word] = enc_index\n",
    "        ind2Word_enc[enc_index] = word \n",
    "        enc_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9BR3MZbR5D5"
   },
   "outputs": [],
   "source": [
    "encoder_input = [[word2Index_enc[word] for word in sentence.split() if word in word2Index_enc.keys()] for sentence in new_source ]\n",
    "decoder_input = [[word2Index_dec[word] for word in sentence.split() if word in word2Index_dec.keys()] for sentence in new_summary ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1Xrg0kzCW5D"
   },
   "outputs": [],
   "source": [
    "encoder_tensor = [torch.tensor(li ,dtype=torch.long,device=device).view(-1, 1) for li in encoder_input]\n",
    "decoder_tensor = [torch.tensor(li,dtype=torch.long,device=device).view(-1, 1) for li in decoder_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErsV--5vShLH"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.gru_layer = nn.GRU(input_size = self.hidden_size,\n",
    "                                hidden_size = self.hidden_size,\n",
    "                                num_layers = self.num_layers,\n",
    "                               bidirectional = self.bidirectional)\n",
    "    \n",
    "\n",
    "    def forward(self, input_, prev_hidden_state):\n",
    "        #get the input word from the index\n",
    "        input_word = ind2Word_enc[input_.data.tolist()[0]] \n",
    "        \n",
    "        #get the weights (vector encoding of that word) from the FastText encoding\n",
    "        embedded_outputs = torch.tensor(weights[input_word], device = device).view(1,1,-1) \n",
    "        \n",
    "        #input has to be (seq_length, batch_size, input_size)\n",
    "        #output will be (seq_length, batch_size, D * hidden_size)\n",
    "        output,prev_hidden_state = self.gru_layer(embedded_outputs, prev_hidden_state)  \n",
    "        hidden = prev_hidden_state\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        #hidden has to be ((D * num_layers), batch_size, hidden_size)\n",
    "        return torch.zeros(self.num_directions * self.num_layers,batch_size,self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I29Rw8CA7esY"
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, output_vocab_size, hidden_size, max_length_encoder, dropout_value, num_layers=1):\n",
    "        super(AttentionDecoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.dropout_p = dropout_value\n",
    "        self.max_length_encoder = max_length_encoder\n",
    "        self.embedding_layer = nn.Embedding(self.output_vocab_size, self.hidden_size)\n",
    "        self.attention_layer = nn.Linear(self.hidden_size*2, self.max_length_encoder)\n",
    "        self.attention_combine = nn.Linear(self.hidden_size*3, self.hidden_size)\n",
    "\n",
    "        self.gru_layer = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, self.output_vocab_size)\n",
    "        self.dropout_layer = nn.Dropout(self.dropout_p)\n",
    "\n",
    "    def forward(self, input_, prev_hidden_state, encoder_output):\n",
    "        input_word = ind2Word_dec[input_.data.tolist()[0]]\n",
    "        embedded_outputs = torch.tensor(weights[input_word], device = device).view(1,1,-1)\n",
    "        \n",
    "        embeddings_dropout = self.dropout_layer(embedded_outputs)\n",
    "        #calculate attention layer\n",
    "        attention_layer_output = self.attention_layer(torch.cat((embeddings_dropout[0], prev_hidden_state[0]), 1))\n",
    "        #calculate alphas with softmax\n",
    "        attention_weights = nn.functional.softmax(attention_layer_output, dim=1)\n",
    "        #multiply them with encoder output to get context vector\n",
    "        attention_applied = torch.bmm(attention_weights.unsqueeze(0), encoder_output.unsqueeze(0))\n",
    "        #run it through a linear layer to get logits\n",
    "        attention_combine_logits = self.attention_combine(torch.cat((embeddings_dropout[0], attention_applied[0]), 1)).unsqueeze(0) #since gru requires a batch dimension \n",
    "        #put that through relu\n",
    "        attention_combine_relu = nn.functional.relu(attention_combine_logits)\n",
    "\n",
    "        hidden = prev_hidden_state[-1, :, :].unsqueeze(0) #only using the last hidden state\n",
    "        output,hidden = self.gru_layer(attention_combine_relu, hidden)\n",
    "        output_logits = self.output_layer(output)\n",
    "        output_softmax = nn.functional.log_softmax(output_logits[0], dim=1)\n",
    "        return output_softmax, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y40789vQM8gc"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "batch_size = 1\n",
    "\n",
    "def train(encoder, \n",
    "          decoder, \n",
    "          input_tensor, \n",
    "          target_tensor, \n",
    "          encoder_optimizer, \n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          max_length, \n",
    "          iters):\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_hidden = encoder.init_hidden(batch_size) \n",
    "    #because it's bidirectional\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size * 2, device = device)\n",
    "\n",
    "    input_length = input_tensor.size(0) #number of words in the input\n",
    "    output_length = target_tensor.size(0) #in the output\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "\n",
    "    for encoder_index in range(0, input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[encoder_index], encoder_hidden)\n",
    "        encoder_outputs[encoder_index] = encoder_output[0,0] #keep saving the encoder output\n",
    "\n",
    "    #start the decoder with the start of sentence token\n",
    "    decoder_input = torch.tensor([word2Index_dec[START_TOKEN]],device=device)   \n",
    "    #pass it the encoder hidden as context vector\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for decoder_index in range(output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attentions = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[decoder_index])\n",
    "            decoder_input = target_tensor[decoder_index]\n",
    "    else:\n",
    "        for decoder_index in range(output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attentions = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs) \n",
    "                \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze(1).detach() \n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[decoder_index])\n",
    "            \n",
    "            try:\n",
    "                if decoder_input.item() == word2Index_dec[END_TOKEN]:\n",
    "                    break\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "    loss.backward()\n",
    "    \n",
    "    #clip the gradient\n",
    "    if iters % 20000 == 0:\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 0.4)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), 0.4)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocM_vNF6KTWW"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    if percent != 0:\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBToTQxGLXgI"
   },
   "outputs": [],
   "source": [
    "# Dictionary for creating loss graph\n",
    "loss_graph = {}\n",
    "\n",
    "def train_Iters(encoder, decoder, n_iters, print_every=50, plot_every=100,learning_rate = 0.03):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [random.choice(pairs) for i in range(n_iters)]\n",
    "  \n",
    "    criterion = nn.NLLLoss()\n",
    "    for iters in range(n_iters):\n",
    "        training_pair = training_pairs[iters - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        input_tensor = torch.tensor(input_tensor, dtype=torch.long, device = device).view(-1, 1)\n",
    "        target_tensor = torch.tensor(target_tensor, dtype=torch.long, device = device).view(-1, 1)\n",
    "\n",
    "        loss = train(encoder, decoder, input_tensor, target_tensor,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion,\n",
    "                     max_source_length, iters)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iters % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            progress = iters / n_iters\n",
    "            print('%s (%s %d%%) %.4f' % (timeSince(start, progress), iters, progress * 100, print_loss_avg))\n",
    "\n",
    "            if iters > 0:\n",
    "                loss_graph[iters] = print_loss_avg\n",
    "\n",
    "        if iters % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jgo_fbnFLgxE"
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for enc,dec in zip(encoder_input,decoder_input):\n",
    "    pairs.append([enc,dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAJAoFoJDLrm"
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "rnn_encoder = Encoder(len(word2Index_enc.keys()), hidden_size, num_layers = 4, bidirectional = True).to(device = device)\n",
    "rnn_decoder = AttentionDecoder(len(word2Index_dec.keys()), hidden_size, max_source_length, 0.2).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0 0%) 0.2130\n",
      "0m 23s (- 234m 21s) (50 0%) 11.7906\n",
      "0m 47s (- 235m 13s) (100 0%) 20.4521\n",
      "1m 11s (- 235m 31s) (150 0%) 21.9541\n",
      "1m 32s (- 230m 15s) (200 0%) 21.0891\n",
      "1m 57s (- 233m 41s) (250 0%) 20.0879\n",
      "2m 20s (- 232m 32s) (300 1%) 20.9396\n",
      "2m 43s (- 231m 1s) (350 1%) 26.7564\n",
      "3m 7s (- 231m 10s) (400 1%) 24.0128\n",
      "3m 29s (- 228m 52s) (450 1%) 24.0521\n",
      "3m 53s (- 229m 8s) (500 1%) 28.0386\n",
      "4m 15s (- 228m 19s) (550 1%) 31.5611\n",
      "4m 39s (- 227m 54s) (600 2%) 25.0885\n",
      "5m 0s (- 226m 26s) (650 2%) 29.5116\n",
      "5m 24s (- 226m 8s) (700 2%) 29.6635\n",
      "5m 46s (- 225m 26s) (750 2%) 29.3064\n",
      "6m 10s (- 225m 14s) (800 2%) 24.0360\n",
      "6m 34s (- 225m 19s) (850 2%) 24.6174\n",
      "6m 57s (- 224m 57s) (900 3%) 23.2018\n",
      "7m 22s (- 225m 17s) (950 3%) 30.0088\n",
      "7m 44s (- 224m 32s) (1000 3%) 27.1985\n",
      "8m 8s (- 224m 35s) (1050 3%) 32.4024\n",
      "8m 31s (- 223m 50s) (1100 3%) 26.7417\n",
      "8m 53s (- 223m 13s) (1150 3%) 26.5710\n",
      "9m 16s (- 222m 41s) (1200 4%) 27.0421\n",
      "9m 40s (- 222m 26s) (1250 4%) 31.3199\n",
      "10m 5s (- 222m 58s) (1300 4%) 29.1404\n",
      "10m 29s (- 222m 48s) (1350 4%) 28.4131\n",
      "10m 53s (- 222m 27s) (1400 4%) 25.6674\n",
      "11m 17s (- 222m 16s) (1450 4%) 25.1101\n",
      "11m 41s (- 222m 3s) (1500 5%) 31.4004\n",
      "12m 4s (- 221m 42s) (1550 5%) 25.3643\n",
      "12m 27s (- 221m 9s) (1600 5%) 24.7551\n",
      "12m 51s (- 220m 54s) (1650 5%) 25.6590\n",
      "13m 14s (- 220m 31s) (1700 5%) 23.9976\n",
      "13m 37s (- 220m 1s) (1750 5%) 26.9900\n",
      "14m 2s (- 219m 52s) (1800 6%) 29.0668\n",
      "14m 24s (- 219m 18s) (1850 6%) 26.2192\n",
      "14m 50s (- 219m 26s) (1900 6%) 28.9016\n",
      "15m 13s (- 219m 3s) (1950 6%) 27.5871\n",
      "15m 36s (- 218m 36s) (2000 6%) 24.9667\n",
      "15m 59s (- 218m 8s) (2050 6%) 25.8332\n",
      "16m 23s (- 217m 40s) (2100 7%) 27.8147\n",
      "16m 47s (- 217m 29s) (2150 7%) 25.7687\n",
      "17m 10s (- 217m 6s) (2200 7%) 23.8656\n",
      "17m 33s (- 216m 38s) (2250 7%) 27.9610\n",
      "17m 57s (- 216m 12s) (2300 7%) 23.4996\n",
      "18m 21s (- 216m 4s) (2350 7%) 27.7701\n",
      "18m 45s (- 215m 48s) (2400 8%) 27.2319\n",
      "19m 8s (- 215m 9s) (2450 8%) 27.6117\n",
      "19m 32s (- 214m 54s) (2500 8%) 25.6162\n",
      "19m 56s (- 214m 40s) (2550 8%) 27.2237\n",
      "20m 19s (- 214m 14s) (2600 8%) 28.7597\n",
      "20m 45s (- 214m 9s) (2650 8%) 26.9154\n",
      "21m 10s (- 214m 1s) (2700 9%) 27.2444\n",
      "21m 33s (- 213m 36s) (2750 9%) 29.6085\n",
      "21m 56s (- 213m 12s) (2800 9%) 28.5697\n",
      "22m 19s (- 212m 42s) (2850 9%) 29.0094\n",
      "22m 44s (- 212m 26s) (2900 9%) 24.9943\n",
      "23m 6s (- 211m 55s) (2950 9%) 26.6503\n",
      "23m 30s (- 211m 37s) (3000 10%) 28.4445\n",
      "23m 52s (- 210m 59s) (3050 10%) 23.9355\n",
      "24m 15s (- 210m 27s) (3100 10%) 26.6359\n",
      "24m 37s (- 209m 52s) (3150 10%) 23.7532\n",
      "25m 0s (- 209m 30s) (3200 10%) 29.2732\n",
      "25m 23s (- 208m 57s) (3250 10%) 28.5112\n",
      "25m 46s (- 208m 36s) (3300 11%) 23.4634\n",
      "26m 9s (- 208m 7s) (3350 11%) 24.1111\n",
      "26m 32s (- 207m 39s) (3400 11%) 28.9418\n",
      "26m 56s (- 207m 16s) (3450 11%) 26.5337\n",
      "27m 18s (- 206m 42s) (3500 11%) 24.3181\n",
      "27m 41s (- 206m 18s) (3550 11%) 25.8264\n",
      "28m 5s (- 206m 0s) (3600 12%) 26.4776\n",
      "28m 29s (- 205m 41s) (3650 12%) 24.9678\n",
      "28m 52s (- 205m 17s) (3700 12%) 25.5014\n",
      "29m 17s (- 205m 0s) (3750 12%) 26.2907\n",
      "29m 41s (- 204m 43s) (3800 12%) 23.2415\n",
      "30m 5s (- 204m 22s) (3850 12%) 21.6253\n",
      "30m 28s (- 203m 58s) (3900 13%) 26.9702\n",
      "30m 52s (- 203m 39s) (3950 13%) 26.9453\n",
      "31m 16s (- 203m 19s) (4000 13%) 27.8011\n",
      "31m 40s (- 202m 55s) (4050 13%) 24.8148\n",
      "32m 3s (- 202m 28s) (4100 13%) 22.0855\n",
      "32m 26s (- 202m 5s) (4150 13%) 25.7166\n",
      "32m 52s (- 201m 54s) (4200 14%) 26.8446\n",
      "33m 16s (- 201m 37s) (4250 14%) 22.7041\n",
      "33m 39s (- 201m 12s) (4300 14%) 20.4272\n",
      "34m 2s (- 200m 46s) (4350 14%) 27.1714\n",
      "34m 25s (- 200m 17s) (4400 14%) 28.7190\n",
      "34m 49s (- 199m 59s) (4450 14%) 30.6214\n",
      "35m 13s (- 199m 38s) (4500 15%) 26.5510\n",
      "35m 36s (- 199m 9s) (4550 15%) 24.7233\n",
      "36m 1s (- 198m 52s) (4600 15%) 29.0098\n",
      "36m 24s (- 198m 27s) (4650 15%) 24.0350\n",
      "36m 48s (- 198m 6s) (4700 15%) 26.4581\n",
      "37m 11s (- 197m 40s) (4750 15%) 29.7021\n",
      "37m 34s (- 197m 16s) (4800 16%) 24.1276\n",
      "37m 57s (- 196m 52s) (4850 16%) 29.0071\n",
      "38m 22s (- 196m 34s) (4900 16%) 23.4347\n",
      "38m 47s (- 196m 20s) (4950 16%) 27.2968\n",
      "39m 11s (- 195m 58s) (5000 16%) 25.0937\n",
      "39m 36s (- 195m 39s) (5050 16%) 23.5067\n",
      "39m 59s (- 195m 15s) (5100 17%) 24.9686\n",
      "40m 22s (- 194m 51s) (5150 17%) 23.5856\n",
      "40m 45s (- 194m 24s) (5200 17%) 22.4736\n",
      "41m 8s (- 193m 59s) (5250 17%) 24.4309\n",
      "41m 32s (- 193m 36s) (5300 17%) 26.5440\n",
      "41m 56s (- 193m 14s) (5350 17%) 23.9992\n",
      "42m 19s (- 192m 48s) (5400 18%) 29.2498\n",
      "42m 40s (- 192m 13s) (5450 18%) 23.8371\n",
      "43m 3s (- 191m 48s) (5500 18%) 25.5294\n",
      "43m 26s (- 191m 24s) (5550 18%) 28.9029\n",
      "43m 50s (- 191m 1s) (5600 18%) 24.3772\n",
      "44m 13s (- 190m 34s) (5650 18%) 25.1314\n",
      "44m 36s (- 190m 8s) (5700 19%) 27.4373\n",
      "44m 59s (- 189m 45s) (5750 19%) 27.4026\n",
      "45m 23s (- 189m 23s) (5800 19%) 29.2666\n",
      "45m 45s (- 188m 54s) (5850 19%) 27.4165\n",
      "46m 9s (- 188m 32s) (5900 19%) 26.5401\n",
      "46m 33s (- 188m 10s) (5950 19%) 31.1679\n",
      "46m 53s (- 187m 35s) (6000 20%) 25.1648\n",
      "47m 16s (- 187m 8s) (6050 20%) 26.6368\n",
      "47m 38s (- 186m 40s) (6100 20%) 27.7348\n",
      "48m 0s (- 186m 10s) (6150 20%) 22.0238\n",
      "48m 22s (- 185m 42s) (6200 20%) 26.4064\n",
      "48m 44s (- 185m 13s) (6250 20%) 23.4005\n",
      "49m 7s (- 184m 48s) (6300 21%) 26.5403\n",
      "49m 29s (- 184m 20s) (6350 21%) 27.9443\n",
      "49m 51s (- 183m 49s) (6400 21%) 24.4658\n",
      "50m 13s (- 183m 23s) (6450 21%) 25.2574\n",
      "50m 35s (- 182m 55s) (6500 21%) 21.4965\n",
      "50m 57s (- 182m 27s) (6550 21%) 26.6458\n",
      "51m 19s (- 181m 57s) (6600 22%) 28.8043\n",
      "51m 42s (- 181m 32s) (6650 22%) 28.9363\n",
      "52m 4s (- 181m 5s) (6700 22%) 22.0759\n",
      "52m 26s (- 180m 38s) (6750 22%) 26.4065\n",
      "52m 49s (- 180m 13s) (6800 22%) 26.9935\n",
      "53m 12s (- 179m 50s) (6850 22%) 26.3800\n",
      "53m 34s (- 179m 22s) (6900 23%) 26.5871\n",
      "53m 57s (- 178m 58s) (6950 23%) 24.7640\n",
      "54m 19s (- 178m 28s) (7000 23%) 24.7265\n",
      "54m 40s (- 177m 59s) (7050 23%) 22.4591\n",
      "55m 2s (- 177m 31s) (7100 23%) 24.5154\n",
      "55m 24s (- 177m 4s) (7150 23%) 25.1616\n",
      "55m 46s (- 176m 35s) (7200 24%) 28.1178\n",
      "56m 7s (- 176m 6s) (7250 24%) 25.1502\n",
      "56m 29s (- 175m 40s) (7300 24%) 23.8789\n",
      "56m 51s (- 175m 14s) (7350 24%) 23.8661\n",
      "57m 15s (- 174m 51s) (7400 24%) 26.0265\n",
      "57m 38s (- 174m 29s) (7450 24%) 26.0370\n",
      "58m 1s (- 174m 5s) (7500 25%) 27.9207\n",
      "58m 23s (- 173m 38s) (7550 25%) 25.6277\n",
      "58m 46s (- 173m 13s) (7600 25%) 24.5895\n",
      "59m 9s (- 172m 50s) (7650 25%) 25.2354\n",
      "59m 32s (- 172m 27s) (7700 25%) 27.6798\n",
      "59m 54s (- 172m 0s) (7750 25%) 20.9657\n",
      "60m 17s (- 171m 35s) (7800 26%) 29.2197\n",
      "60m 38s (- 171m 7s) (7850 26%) 28.6588\n",
      "61m 1s (- 170m 43s) (7900 26%) 26.0878\n",
      "61m 22s (- 170m 13s) (7950 26%) 27.5166\n",
      "61m 44s (- 169m 48s) (8000 26%) 23.2995\n",
      "62m 6s (- 169m 22s) (8050 26%) 24.3860\n",
      "62m 29s (- 168m 57s) (8100 27%) 24.4948\n",
      "62m 51s (- 168m 30s) (8150 27%) 24.1882\n",
      "63m 11s (- 168m 0s) (8200 27%) 21.3904\n",
      "63m 34s (- 167m 37s) (8250 27%) 23.2011\n",
      "63m 56s (- 167m 11s) (8300 27%) 30.0015\n",
      "64m 17s (- 166m 42s) (8350 27%) 24.5124\n",
      "64m 41s (- 166m 19s) (8400 28%) 27.0914\n",
      "65m 4s (- 165m 56s) (8450 28%) 21.9791\n",
      "65m 25s (- 165m 30s) (8500 28%) 23.6702\n",
      "65m 47s (- 165m 4s) (8550 28%) 24.1038\n",
      "66m 9s (- 164m 38s) (8600 28%) 25.5635\n",
      "66m 32s (- 164m 14s) (8650 28%) 25.1385\n",
      "66m 53s (- 163m 45s) (8700 28%) 24.5426\n",
      "67m 15s (- 163m 20s) (8750 29%) 24.5908\n",
      "67m 37s (- 162m 54s) (8800 29%) 22.4598\n",
      "68m 0s (- 162m 31s) (8850 29%) 24.7416\n",
      "68m 21s (- 162m 3s) (8900 29%) 25.9148\n",
      "68m 43s (- 161m 39s) (8950 29%) 27.5554\n",
      "69m 6s (- 161m 15s) (9000 30%) 22.1008\n",
      "69m 28s (- 160m 49s) (9050 30%) 28.1066\n",
      "69m 52s (- 160m 28s) (9100 30%) 28.3596\n",
      "70m 14s (- 160m 4s) (9150 30%) 23.3858\n",
      "70m 35s (- 159m 36s) (9200 30%) 29.8796\n",
      "70m 56s (- 159m 8s) (9250 30%) 28.0738\n",
      "71m 18s (- 158m 43s) (9300 31%) 25.2404\n",
      "71m 40s (- 158m 18s) (9350 31%) 26.0390\n",
      "72m 2s (- 157m 53s) (9400 31%) 27.6512\n",
      "72m 25s (- 157m 30s) (9450 31%) 25.4148\n",
      "72m 48s (- 157m 5s) (9500 31%) 21.3103\n",
      "73m 9s (- 156m 39s) (9550 31%) 22.6012\n",
      "73m 31s (- 156m 15s) (9600 32%) 21.7084\n",
      "73m 54s (- 155m 50s) (9650 32%) 24.7457\n",
      "74m 16s (- 155m 25s) (9700 32%) 23.2786\n",
      "74m 37s (- 154m 58s) (9750 32%) 25.7663\n",
      "74m 59s (- 154m 33s) (9800 32%) 23.9035\n",
      "75m 20s (- 154m 7s) (9850 32%) 23.9112\n",
      "75m 43s (- 153m 43s) (9900 33%) 24.6938\n",
      "76m 3s (- 153m 16s) (9950 33%) 23.6519\n",
      "76m 25s (- 152m 50s) (10000 33%) 24.2854\n",
      "76m 47s (- 152m 26s) (10050 33%) 24.3948\n",
      "77m 9s (- 152m 0s) (10100 33%) 19.6230\n",
      "77m 29s (- 151m 32s) (10150 33%) 21.8236\n",
      "77m 51s (- 151m 7s) (10200 34%) 27.4821\n",
      "78m 12s (- 150m 41s) (10250 34%) 24.3942\n",
      "78m 35s (- 150m 19s) (10300 34%) 24.7766\n",
      "78m 58s (- 149m 55s) (10350 34%) 29.1611\n",
      "79m 21s (- 149m 33s) (10400 34%) 27.4463\n",
      "79m 43s (- 149m 8s) (10450 34%) 24.4941\n",
      "80m 6s (- 148m 46s) (10500 35%) 23.7264\n",
      "80m 28s (- 148m 21s) (10550 35%) 24.8272\n",
      "80m 50s (- 147m 58s) (10600 35%) 24.3677\n",
      "81m 14s (- 147m 37s) (10650 35%) 24.9083\n",
      "81m 40s (- 147m 18s) (10700 35%) 27.9222\n",
      "82m 1s (- 146m 53s) (10750 35%) 25.4742\n",
      "82m 26s (- 146m 33s) (10800 36%) 25.4187\n",
      "82m 49s (- 146m 11s) (10850 36%) 24.8795\n",
      "83m 14s (- 145m 51s) (10900 36%) 24.5984\n",
      "83m 38s (- 145m 30s) (10950 36%) 20.0282\n",
      "84m 0s (- 145m 6s) (11000 36%) 23.6908\n",
      "84m 24s (- 144m 45s) (11050 36%) 22.7291\n",
      "84m 48s (- 144m 24s) (11100 37%) 27.3161\n",
      "85m 11s (- 144m 1s) (11150 37%) 25.9608\n",
      "85m 35s (- 143m 40s) (11200 37%) 23.9321\n",
      "85m 59s (- 143m 18s) (11250 37%) 26.6578\n",
      "86m 21s (- 142m 55s) (11300 37%) 25.7259\n",
      "86m 45s (- 142m 32s) (11350 37%) 24.0263\n",
      "87m 8s (- 142m 10s) (11400 38%) 26.6556\n",
      "87m 32s (- 141m 49s) (11450 38%) 24.1755\n",
      "87m 56s (- 141m 28s) (11500 38%) 22.5613\n",
      "88m 18s (- 141m 4s) (11550 38%) 23.9742\n",
      "88m 41s (- 140m 41s) (11600 38%) 20.6649\n",
      "89m 6s (- 140m 21s) (11650 38%) 29.0512\n",
      "89m 29s (- 139m 58s) (11700 39%) 21.1232\n",
      "89m 53s (- 139m 37s) (11750 39%) 18.9125\n",
      "90m 18s (- 139m 17s) (11800 39%) 22.6501\n",
      "90m 42s (- 138m 56s) (11850 39%) 20.4757\n",
      "91m 5s (- 138m 33s) (11900 39%) 26.3632\n",
      "91m 28s (- 138m 10s) (11950 39%) 25.6624\n",
      "91m 51s (- 137m 47s) (12000 40%) 21.3861\n",
      "92m 14s (- 137m 24s) (12050 40%) 23.4708\n",
      "92m 37s (- 137m 2s) (12100 40%) 23.2295\n",
      "93m 0s (- 136m 39s) (12150 40%) 22.7234\n",
      "93m 24s (- 136m 17s) (12200 40%) 23.8541\n",
      "93m 48s (- 135m 56s) (12250 40%) 25.2558\n",
      "94m 12s (- 135m 33s) (12300 41%) 27.3872\n",
      "94m 35s (- 135m 11s) (12350 41%) 26.3719\n",
      "94m 59s (- 134m 49s) (12400 41%) 20.6917\n",
      "95m 23s (- 134m 28s) (12450 41%) 26.9246\n",
      "95m 46s (- 134m 5s) (12500 41%) 23.7263\n",
      "96m 9s (- 133m 41s) (12550 41%) 20.8009\n",
      "96m 32s (- 133m 19s) (12600 42%) 25.2496\n",
      "96m 55s (- 132m 56s) (12650 42%) 22.3912\n",
      "97m 20s (- 132m 35s) (12700 42%) 23.1985\n",
      "97m 43s (- 132m 13s) (12750 42%) 21.8678\n",
      "98m 7s (- 131m 51s) (12800 42%) 21.5418\n",
      "98m 31s (- 131m 29s) (12850 42%) 17.9103\n",
      "98m 55s (- 131m 8s) (12900 43%) 22.2116\n",
      "99m 22s (- 130m 50s) (12950 43%) 21.5508\n",
      "99m 51s (- 130m 34s) (13000 43%) 24.2755\n",
      "100m 16s (- 130m 14s) (13050 43%) 23.3694\n",
      "100m 41s (- 129m 54s) (13100 43%) 24.5932\n",
      "101m 5s (- 129m 32s) (13150 43%) 19.3723\n",
      "101m 29s (- 129m 10s) (13200 44%) 24.6418\n",
      "101m 51s (- 128m 46s) (13250 44%) 22.2485\n",
      "102m 14s (- 128m 22s) (13300 44%) 21.8073\n",
      "102m 37s (- 127m 59s) (13350 44%) 20.6335\n",
      "103m 1s (- 127m 37s) (13400 44%) 23.6286\n",
      "103m 24s (- 127m 14s) (13450 44%) 23.5008\n",
      "103m 48s (- 126m 52s) (13500 45%) 26.5188\n",
      "104m 12s (- 126m 31s) (13550 45%) 26.6231\n",
      "104m 35s (- 126m 7s) (13600 45%) 25.1940\n",
      "105m 0s (- 125m 46s) (13650 45%) 20.6852\n",
      "105m 23s (- 125m 23s) (13700 45%) 19.0963\n",
      "105m 46s (- 125m 0s) (13750 45%) 20.6359\n",
      "106m 11s (- 124m 39s) (13800 46%) 23.8080\n",
      "106m 35s (- 124m 17s) (13850 46%) 25.8395\n",
      "106m 59s (- 123m 55s) (13900 46%) 25.6429\n",
      "107m 24s (- 123m 34s) (13950 46%) 25.4068\n",
      "107m 50s (- 123m 14s) (14000 46%) 23.4130\n",
      "108m 13s (- 122m 51s) (14050 46%) 20.9621\n",
      "108m 35s (- 122m 27s) (14100 47%) 25.0935\n",
      "108m 57s (- 122m 2s) (14150 47%) 20.4063\n",
      "109m 19s (- 121m 39s) (14200 47%) 22.6584\n",
      "109m 44s (- 121m 17s) (14250 47%) 28.9175\n",
      "110m 8s (- 120m 55s) (14300 47%) 21.8848\n",
      "110m 32s (- 120m 33s) (14350 47%) 22.2611\n",
      "110m 57s (- 120m 12s) (14400 48%) 22.9340\n",
      "111m 22s (- 119m 51s) (14450 48%) 23.8764\n",
      "111m 47s (- 119m 30s) (14500 48%) 27.6920\n",
      "112m 11s (- 119m 7s) (14550 48%) 21.3348\n",
      "112m 34s (- 118m 44s) (14600 48%) 22.1614\n",
      "112m 58s (- 118m 22s) (14650 48%) 24.4326\n",
      "113m 24s (- 118m 2s) (14700 49%) 26.9616\n",
      "113m 47s (- 117m 38s) (14750 49%) 20.8926\n",
      "114m 10s (- 117m 15s) (14800 49%) 21.8692\n",
      "114m 33s (- 116m 52s) (14850 49%) 25.1890\n",
      "114m 54s (- 116m 27s) (14900 49%) 22.4571\n",
      "115m 18s (- 116m 4s) (14950 49%) 23.9353\n",
      "115m 41s (- 115m 41s) (15000 50%) 22.4063\n",
      "116m 5s (- 115m 19s) (15050 50%) 23.0507\n",
      "116m 28s (- 114m 56s) (15100 50%) 18.5537\n",
      "116m 53s (- 114m 34s) (15150 50%) 22.5563\n",
      "117m 17s (- 114m 11s) (15200 50%) 31.8562\n",
      "117m 39s (- 113m 48s) (15250 50%) 21.5267\n",
      "118m 2s (- 113m 24s) (15300 51%) 22.3238\n",
      "118m 26s (- 113m 2s) (15350 51%) 21.8904\n",
      "118m 48s (- 112m 38s) (15400 51%) 23.8759\n",
      "119m 14s (- 112m 17s) (15450 51%) 25.7061\n",
      "119m 38s (- 111m 55s) (15500 51%) 26.0892\n",
      "120m 1s (- 111m 31s) (15550 51%) 24.9491\n",
      "120m 24s (- 111m 8s) (15600 52%) 21.8776\n",
      "120m 47s (- 110m 45s) (15650 52%) 22.6509\n",
      "121m 9s (- 110m 21s) (15700 52%) 28.2316\n",
      "121m 32s (- 109m 57s) (15750 52%) 19.2079\n",
      "121m 56s (- 109m 35s) (15800 52%) 22.9049\n",
      "122m 18s (- 109m 11s) (15850 52%) 17.7129\n",
      "122m 43s (- 108m 50s) (15900 53%) 25.9345\n",
      "123m 7s (- 108m 27s) (15950 53%) 22.0804\n",
      "123m 31s (- 108m 4s) (16000 53%) 26.7651\n",
      "123m 55s (- 107m 42s) (16050 53%) 23.7490\n",
      "124m 17s (- 107m 18s) (16100 53%) 23.6740\n",
      "124m 40s (- 106m 55s) (16150 53%) 19.5721\n",
      "125m 6s (- 106m 34s) (16200 54%) 27.3357\n",
      "125m 33s (- 106m 14s) (16250 54%) 25.1083\n",
      "125m 57s (- 105m 51s) (16300 54%) 19.4837\n",
      "126m 24s (- 105m 32s) (16350 54%) 25.8940\n",
      "126m 53s (- 105m 13s) (16400 54%) 23.9348\n",
      "127m 18s (- 104m 52s) (16450 54%) 21.4650\n",
      "127m 40s (- 104m 27s) (16500 55%) 18.7204\n",
      "128m 1s (- 104m 2s) (16550 55%) 20.4655\n",
      "128m 24s (- 103m 39s) (16600 55%) 21.9557\n",
      "128m 49s (- 103m 17s) (16650 55%) 22.1470\n",
      "129m 17s (- 102m 58s) (16700 55%) 22.1505\n",
      "129m 40s (- 102m 34s) (16750 55%) 21.3537\n",
      "130m 5s (- 102m 13s) (16800 56%) 27.6486\n",
      "130m 29s (- 101m 50s) (16850 56%) 22.4584\n",
      "130m 52s (- 101m 26s) (16900 56%) 22.8600\n",
      "131m 16s (- 101m 4s) (16950 56%) 21.4642\n",
      "131m 41s (- 100m 42s) (17000 56%) 24.0752\n",
      "132m 4s (- 100m 19s) (17050 56%) 20.3295\n",
      "132m 28s (- 99m 56s) (17100 56%) 21.8357\n",
      "132m 51s (- 99m 33s) (17150 57%) 20.6347\n",
      "133m 16s (- 99m 10s) (17200 57%) 22.7119\n",
      "133m 41s (- 98m 49s) (17250 57%) 21.4797\n",
      "134m 8s (- 98m 28s) (17300 57%) 24.0833\n",
      "134m 31s (- 98m 4s) (17350 57%) 23.7537\n",
      "134m 53s (- 97m 41s) (17400 57%) 26.5280\n",
      "135m 18s (- 97m 18s) (17450 58%) 20.8476\n",
      "135m 41s (- 96m 55s) (17500 58%) 19.6169\n",
      "136m 5s (- 96m 32s) (17550 58%) 22.7729\n",
      "136m 30s (- 96m 10s) (17600 58%) 22.3492\n",
      "136m 55s (- 95m 48s) (17650 58%) 21.7910\n",
      "137m 19s (- 95m 25s) (17700 59%) 18.7468\n",
      "137m 43s (- 95m 2s) (17750 59%) 18.7424\n",
      "138m 8s (- 94m 40s) (17800 59%) 20.8023\n",
      "138m 31s (- 94m 17s) (17850 59%) 26.4887\n",
      "138m 55s (- 93m 54s) (17900 59%) 21.8175\n",
      "139m 20s (- 93m 32s) (17950 59%) 20.0131\n",
      "139m 46s (- 93m 10s) (18000 60%) 23.0767\n",
      "140m 11s (- 92m 48s) (18050 60%) 21.2909\n",
      "140m 34s (- 92m 25s) (18100 60%) 19.8842\n",
      "141m 2s (- 92m 5s) (18150 60%) 27.4651\n",
      "141m 28s (- 91m 43s) (18200 60%) 26.0832\n",
      "141m 53s (- 91m 21s) (18250 60%) 24.5892\n",
      "142m 18s (- 90m 59s) (18300 61%) 21.1162\n",
      "142m 43s (- 90m 36s) (18350 61%) 20.3112\n",
      "143m 8s (- 90m 14s) (18400 61%) 23.8335\n",
      "143m 33s (- 89m 51s) (18450 61%) 19.2120\n",
      "143m 57s (- 89m 29s) (18500 61%) 19.9990\n",
      "144m 25s (- 89m 8s) (18550 61%) 18.2143\n",
      "144m 49s (- 88m 45s) (18600 62%) 18.2519\n",
      "145m 14s (- 88m 23s) (18650 62%) 23.2620\n",
      "145m 39s (- 88m 0s) (18700 62%) 23.1486\n",
      "146m 4s (- 87m 38s) (18750 62%) 24.8547\n",
      "146m 29s (- 87m 16s) (18800 62%) 20.6727\n",
      "146m 53s (- 86m 53s) (18850 62%) 23.8588\n",
      "147m 16s (- 86m 29s) (18900 63%) 19.3341\n",
      "147m 42s (- 86m 7s) (18950 63%) 21.8533\n",
      "148m 9s (- 85m 46s) (19000 63%) 24.6390\n",
      "148m 33s (- 85m 23s) (19050 63%) 19.9237\n",
      "148m 58s (- 85m 0s) (19100 63%) 20.0615\n",
      "149m 23s (- 84m 38s) (19150 63%) 23.7301\n",
      "149m 47s (- 84m 15s) (19200 64%) 20.4949\n",
      "150m 11s (- 83m 52s) (19250 64%) 22.6121\n",
      "150m 34s (- 83m 28s) (19300 64%) 25.5260\n",
      "150m 58s (- 83m 5s) (19350 64%) 21.8515\n",
      "151m 20s (- 82m 41s) (19400 64%) 23.4614\n",
      "151m 44s (- 82m 18s) (19450 64%) 23.0794\n",
      "152m 6s (- 81m 54s) (19500 65%) 17.5252\n",
      "152m 30s (- 81m 31s) (19550 65%) 22.6368\n",
      "152m 55s (- 81m 8s) (19600 65%) 29.9930\n",
      "153m 19s (- 80m 45s) (19650 65%) 23.5077\n",
      "153m 43s (- 80m 22s) (19700 65%) 22.3929\n",
      "154m 6s (- 79m 58s) (19750 65%) 17.3892\n",
      "154m 29s (- 79m 35s) (19800 66%) 22.0969\n",
      "154m 53s (- 79m 12s) (19850 66%) 19.0909\n",
      "155m 18s (- 78m 49s) (19900 66%) 23.1514\n",
      "155m 40s (- 78m 25s) (19950 66%) 26.6472\n",
      "156m 5s (- 78m 2s) (20000 66%) 19.8896\n",
      "156m 28s (- 77m 39s) (20050 66%) 22.9134\n",
      "156m 52s (- 77m 16s) (20100 67%) 20.6604\n",
      "157m 14s (- 76m 51s) (20150 67%) 20.5964\n",
      "157m 38s (- 76m 28s) (20200 67%) 24.6064\n",
      "158m 2s (- 76m 5s) (20250 67%) 22.4977\n",
      "158m 26s (- 75m 42s) (20300 67%) 21.4723\n",
      "158m 50s (- 75m 19s) (20350 67%) 22.3942\n",
      "159m 15s (- 74m 56s) (20400 68%) 19.1049\n",
      "159m 38s (- 74m 33s) (20450 68%) 20.7807\n",
      "160m 3s (- 74m 10s) (20500 68%) 20.5661\n",
      "160m 28s (- 73m 47s) (20550 68%) 23.2646\n",
      "160m 51s (- 73m 23s) (20600 68%) 20.4200\n",
      "161m 16s (- 73m 1s) (20650 68%) 22.0358\n",
      "161m 40s (- 72m 38s) (20700 69%) 22.5432\n",
      "162m 5s (- 72m 15s) (20750 69%) 23.8739\n",
      "162m 32s (- 71m 53s) (20800 69%) 25.3100\n",
      "162m 58s (- 71m 31s) (20850 69%) 22.8569\n",
      "163m 23s (- 71m 8s) (20900 69%) 23.5222\n",
      "163m 49s (- 70m 46s) (20950 69%) 23.3800\n",
      "164m 15s (- 70m 23s) (21000 70%) 20.3779\n",
      "164m 44s (- 70m 2s) (21050 70%) 24.8446\n",
      "165m 10s (- 69m 40s) (21100 70%) 23.4016\n",
      "165m 33s (- 69m 16s) (21150 70%) 19.9217\n",
      "165m 58s (- 68m 53s) (21200 70%) 25.6887\n",
      "166m 23s (- 68m 30s) (21250 70%) 21.4901\n",
      "166m 50s (- 68m 8s) (21300 71%) 25.0175\n",
      "167m 16s (- 67m 46s) (21350 71%) 24.5791\n",
      "167m 41s (- 67m 23s) (21400 71%) 22.6522\n",
      "168m 8s (- 67m 1s) (21450 71%) 25.2766\n",
      "168m 35s (- 66m 39s) (21500 71%) 23.4174\n",
      "169m 0s (- 66m 16s) (21550 71%) 18.8765\n",
      "169m 25s (- 65m 53s) (21600 72%) 18.2174\n",
      "169m 49s (- 65m 30s) (21650 72%) 20.2612\n",
      "170m 14s (- 65m 6s) (21700 72%) 26.3741\n",
      "170m 39s (- 64m 43s) (21750 72%) 22.8808\n",
      "171m 4s (- 64m 21s) (21800 72%) 23.4362\n",
      "171m 29s (- 63m 57s) (21850 72%) 22.6825\n",
      "171m 56s (- 63m 35s) (21900 73%) 20.2628\n",
      "172m 22s (- 63m 12s) (21950 73%) 23.3939\n",
      "172m 46s (- 62m 49s) (22000 73%) 21.0557\n",
      "173m 11s (- 62m 26s) (22050 73%) 23.9999\n",
      "173m 34s (- 62m 2s) (22100 73%) 21.6147\n",
      "173m 59s (- 61m 39s) (22150 73%) 24.0595\n",
      "174m 24s (- 61m 16s) (22200 74%) 24.0961\n",
      "174m 49s (- 60m 53s) (22250 74%) 24.2633\n",
      "175m 14s (- 60m 30s) (22300 74%) 28.5647\n",
      "175m 38s (- 60m 7s) (22350 74%) 20.9332\n",
      "176m 2s (- 59m 43s) (22400 74%) 19.6347\n",
      "176m 26s (- 59m 20s) (22450 74%) 21.2976\n",
      "176m 52s (- 58m 57s) (22500 75%) 26.0294\n",
      "177m 16s (- 58m 34s) (22550 75%) 19.3124\n",
      "177m 42s (- 58m 11s) (22600 75%) 22.6153\n",
      "178m 6s (- 57m 47s) (22650 75%) 23.2561\n",
      "178m 31s (- 57m 24s) (22700 75%) 23.2821\n",
      "178m 58s (- 57m 2s) (22750 75%) 19.8479\n",
      "179m 24s (- 56m 39s) (22800 76%) 20.2955\n",
      "179m 49s (- 56m 16s) (22850 76%) 24.0165\n",
      "180m 14s (- 55m 52s) (22900 76%) 21.8971\n",
      "180m 40s (- 55m 30s) (22950 76%) 18.8739\n",
      "181m 5s (- 55m 6s) (23000 76%) 22.9238\n",
      "181m 32s (- 54m 44s) (23050 76%) 23.8371\n",
      "181m 58s (- 54m 21s) (23100 77%) 23.2452\n",
      "182m 22s (- 53m 57s) (23150 77%) 21.2508\n",
      "182m 47s (- 53m 34s) (23200 77%) 17.0556\n",
      "183m 13s (- 53m 11s) (23250 77%) 22.6617\n",
      "183m 40s (- 52m 49s) (23300 77%) 19.0235\n",
      "184m 8s (- 52m 26s) (23350 77%) 19.7712\n",
      "184m 33s (- 52m 3s) (23400 78%) 22.6341\n",
      "184m 57s (- 51m 39s) (23450 78%) 21.8960\n",
      "185m 21s (- 51m 16s) (23500 78%) 23.9754\n",
      "185m 45s (- 50m 52s) (23550 78%) 23.3438\n",
      "186m 10s (- 50m 29s) (23600 78%) 22.2159\n",
      "186m 34s (- 50m 5s) (23650 78%) 22.9070\n",
      "186m 58s (- 49m 42s) (23700 79%) 20.5821\n",
      "187m 26s (- 49m 19s) (23750 79%) 25.1556\n",
      "187m 52s (- 48m 56s) (23800 79%) 24.6431\n",
      "188m 17s (- 48m 33s) (23850 79%) 20.5777\n",
      "188m 43s (- 48m 10s) (23900 79%) 23.9178\n",
      "189m 10s (- 47m 47s) (23950 79%) 22.7728\n",
      "189m 35s (- 47m 23s) (24000 80%) 25.9716\n",
      "189m 58s (- 47m 0s) (24050 80%) 24.2067\n",
      "190m 23s (- 46m 36s) (24100 80%) 23.2179\n",
      "190m 49s (- 46m 13s) (24150 80%) 24.5499\n",
      "191m 12s (- 45m 49s) (24200 80%) 21.4414\n",
      "191m 37s (- 45m 26s) (24250 80%) 24.1673\n",
      "192m 2s (- 45m 2s) (24300 81%) 25.1951\n",
      "192m 27s (- 44m 39s) (24350 81%) 23.1859\n",
      "192m 53s (- 44m 16s) (24400 81%) 23.9808\n",
      "193m 20s (- 43m 53s) (24450 81%) 24.3004\n",
      "193m 46s (- 43m 29s) (24500 81%) 23.2275\n",
      "194m 11s (- 43m 6s) (24550 81%) 22.5297\n",
      "194m 35s (- 42m 42s) (24600 82%) 25.3666\n",
      "195m 0s (- 42m 19s) (24650 82%) 20.8522\n",
      "195m 26s (- 41m 56s) (24700 82%) 22.9637\n",
      "195m 50s (- 41m 32s) (24750 82%) 16.1401\n",
      "196m 17s (- 41m 9s) (24800 82%) 21.4855\n",
      "196m 41s (- 40m 45s) (24850 82%) 18.1828\n",
      "197m 7s (- 40m 22s) (24900 83%) 16.9611\n",
      "197m 32s (- 39m 59s) (24950 83%) 19.6820\n",
      "197m 57s (- 39m 35s) (25000 83%) 21.8412\n",
      "198m 23s (- 39m 12s) (25050 83%) 21.0887\n",
      "198m 47s (- 38m 48s) (25100 83%) 21.6866\n",
      "199m 11s (- 38m 24s) (25150 83%) 19.3713\n",
      "199m 36s (- 38m 1s) (25200 84%) 22.9066\n",
      "200m 3s (- 37m 38s) (25250 84%) 23.6157\n",
      "200m 28s (- 37m 14s) (25300 84%) 21.2881\n",
      "200m 53s (- 36m 51s) (25350 84%) 20.0280\n",
      "201m 19s (- 36m 27s) (25400 84%) 20.2598\n",
      "201m 43s (- 36m 3s) (25450 84%) 17.8719\n",
      "202m 8s (- 35m 40s) (25500 85%) 22.4428\n",
      "202m 33s (- 35m 16s) (25550 85%) 22.3756\n",
      "202m 59s (- 34m 53s) (25600 85%) 26.6989\n",
      "203m 24s (- 34m 29s) (25650 85%) 19.2760\n",
      "203m 48s (- 34m 6s) (25700 85%) 22.2840\n",
      "204m 13s (- 33m 42s) (25750 85%) 20.8993\n",
      "204m 38s (- 33m 18s) (25800 86%) 22.4977\n",
      "205m 5s (- 32m 55s) (25850 86%) 26.8904\n",
      "205m 32s (- 32m 32s) (25900 86%) 26.9305\n",
      "205m 58s (- 32m 8s) (25950 86%) 26.1085\n",
      "206m 23s (- 31m 45s) (26000 86%) 23.5868\n",
      "206m 47s (- 31m 21s) (26050 86%) 20.5000\n",
      "207m 12s (- 30m 57s) (26100 87%) 19.3331\n",
      "207m 37s (- 30m 34s) (26150 87%) 22.2709\n",
      "208m 2s (- 30m 10s) (26200 87%) 18.7561\n",
      "208m 26s (- 29m 46s) (26250 87%) 18.8632\n",
      "208m 52s (- 29m 23s) (26300 87%) 24.4796\n",
      "209m 17s (- 28m 59s) (26350 87%) 24.0241\n",
      "209m 42s (- 28m 35s) (26400 88%) 24.5085\n",
      "210m 7s (- 28m 12s) (26450 88%) 22.1067\n",
      "210m 33s (- 27m 48s) (26500 88%) 19.3047\n",
      "210m 59s (- 27m 24s) (26550 88%) 18.0190\n",
      "211m 23s (- 27m 1s) (26600 88%) 20.2816\n",
      "211m 47s (- 26m 37s) (26650 88%) 19.3394\n",
      "212m 11s (- 26m 13s) (26700 89%) 23.6506\n",
      "212m 37s (- 25m 49s) (26750 89%) 21.9864\n",
      "213m 2s (- 25m 26s) (26800 89%) 21.1593\n",
      "213m 28s (- 25m 2s) (26850 89%) 21.0098\n",
      "213m 53s (- 24m 38s) (26900 89%) 18.2511\n",
      "214m 17s (- 24m 15s) (26950 89%) 21.7966\n",
      "214m 41s (- 23m 51s) (27000 90%) 19.5323\n",
      "215m 6s (- 23m 27s) (27050 90%) 21.2533\n",
      "215m 32s (- 23m 3s) (27100 90%) 22.4284\n",
      "215m 59s (- 22m 40s) (27150 90%) 23.9494\n",
      "216m 25s (- 22m 16s) (27200 90%) 21.2742\n",
      "216m 48s (- 21m 52s) (27250 90%) 20.1955\n",
      "217m 13s (- 21m 29s) (27300 91%) 21.3851\n",
      "217m 38s (- 21m 5s) (27350 91%) 25.0177\n",
      "218m 3s (- 20m 41s) (27400 91%) 26.0676\n",
      "218m 27s (- 20m 17s) (27450 91%) 18.5515\n",
      "218m 52s (- 19m 53s) (27500 91%) 22.7273\n",
      "219m 16s (- 19m 29s) (27550 91%) 20.6672\n",
      "219m 41s (- 19m 6s) (27600 92%) 22.3830\n",
      "220m 7s (- 18m 42s) (27650 92%) 22.7895\n",
      "220m 30s (- 18m 18s) (27700 92%) 19.4886\n",
      "220m 54s (- 17m 54s) (27750 92%) 22.5498\n",
      "221m 17s (- 17m 30s) (27800 92%) 20.0557\n",
      "221m 43s (- 17m 7s) (27850 92%) 20.6867\n",
      "222m 9s (- 16m 43s) (27900 93%) 19.7894\n",
      "222m 33s (- 16m 19s) (27950 93%) 21.2066\n",
      "222m 58s (- 15m 55s) (28000 93%) 21.4563\n",
      "223m 22s (- 15m 31s) (28050 93%) 24.8974\n",
      "223m 47s (- 15m 7s) (28100 93%) 24.9164\n",
      "224m 12s (- 14m 44s) (28150 93%) 23.3863\n",
      "224m 37s (- 14m 20s) (28200 94%) 23.2981\n",
      "225m 3s (- 13m 56s) (28250 94%) 18.2265\n",
      "225m 29s (- 13m 32s) (28300 94%) 26.9955\n",
      "225m 54s (- 13m 8s) (28350 94%) 20.4802\n",
      "226m 18s (- 12m 45s) (28400 94%) 23.5064\n",
      "226m 43s (- 12m 21s) (28450 94%) 18.6512\n",
      "227m 8s (- 11m 57s) (28500 95%) 22.8809\n",
      "227m 34s (- 11m 33s) (28550 95%) 24.8039\n",
      "227m 59s (- 11m 9s) (28600 95%) 23.4774\n",
      "228m 25s (- 10m 45s) (28650 95%) 17.9110\n",
      "228m 51s (- 10m 22s) (28700 95%) 19.2025\n",
      "229m 15s (- 9m 58s) (28750 95%) 26.4736\n",
      "229m 41s (- 9m 34s) (28800 96%) 26.7767\n",
      "230m 5s (- 9m 10s) (28850 96%) 17.8003\n",
      "230m 29s (- 8m 46s) (28900 96%) 16.0278\n",
      "230m 55s (- 8m 22s) (28950 96%) 20.2480\n",
      "231m 21s (- 7m 58s) (29000 96%) 24.7717\n",
      "231m 45s (- 7m 34s) (29050 96%) 20.0676\n",
      "232m 11s (- 7m 10s) (29100 97%) 22.8026\n",
      "232m 34s (- 6m 46s) (29150 97%) 20.5198\n",
      "233m 1s (- 6m 23s) (29200 97%) 23.5651\n",
      "233m 26s (- 5m 59s) (29250 97%) 22.3344\n",
      "233m 49s (- 5m 35s) (29300 97%) 18.2680\n",
      "234m 14s (- 5m 11s) (29350 97%) 25.9489\n",
      "234m 38s (- 4m 47s) (29400 98%) 22.8480\n",
      "235m 4s (- 4m 23s) (29450 98%) 24.7031\n",
      "235m 28s (- 3m 59s) (29500 98%) 19.2320\n",
      "235m 54s (- 3m 35s) (29550 98%) 20.2778\n",
      "236m 21s (- 3m 11s) (29600 98%) 21.7928\n",
      "236m 48s (- 2m 47s) (29650 98%) 25.0567\n",
      "237m 11s (- 2m 23s) (29700 99%) 20.8268\n",
      "237m 36s (- 1m 59s) (29750 99%) 22.5043\n",
      "238m 0s (- 1m 35s) (29800 99%) 21.7132\n",
      "238m 25s (- 1m 11s) (29850 99%) 22.6674\n",
      "238m 51s (- 0m 47s) (29900 99%) 21.4923\n",
      "239m 16s (- 0m 23s) (29950 99%) 21.7101\n"
     ]
    }
   ],
   "source": [
    "train_Iters(rnn_encoder, rnn_decoder, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = './cnn_enc_attention.w'\n",
    "decoder_path = './cnn_decoder_attention.w'\n",
    "torch.save(rnn_encoder.state_dict(), encoder_path)\n",
    "torch.save(rnn_decoder.state_dict(), decoder_path)\n",
    "\n",
    "#rnn_encoder.load_state_dict(torch.load(encoder_path))\n",
    "#rnn_encoder.eval()\n",
    "#rnn_decoder.load_state_dict(torch.load(decoder_path))\n",
    "#rnn_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IbiBvMaDO3k"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iters = list(loss_graph.keys())\n",
    "loss_val = list(loss_graph.values())\n",
    "plt.plot(iters, loss_val) \n",
    "plt.xlabel('Iterations') \n",
    "plt.ylabel('Loss')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHA9RnrZgk6j"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        pair1 = torch.tensor(pair[0],dtype=torch.long,device=device)\n",
    "        pair2 = pair[1]\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair1)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        output_list = [ind2Word_dec[word] for word in pair2]\n",
    "        output_list = ' '.join(output_list)\n",
    "        input_sentence = [ind2Word_enc[element.item()] for element in pair1.flatten()]\n",
    "        input_sentence = ' '.join(input_sentence)\n",
    "        print(\"Article = \",input_sentence)\n",
    "        print('\\n Predicted Summary = ', output_sentence)\n",
    "        print('\\n Reference Summary =', output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObARxnAyoUTA"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, encoder_tensor, max_length = max_source_length):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = encoder_tensor\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.init_hidden(batch_size)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size * 2, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0),\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([word2Index_dec[START_TOKEN]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_summary_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if ind2Word_dec[topi.item()] == END_TOKEN:\n",
    "                decoded_words.append(END_TOKEN)\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ind2Word_dec[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze(1).detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYYHCcO04vV5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article =  despite their inconsistent start to the season and an injury crisis that has left their squad bereft of some world class talent manchester united s players appear to be in good spirits ahead of their clash against arsenal on saturday david de gea was a doubt for the match after dislocating his finger on international duty with spain but trained with the squad and was all smiles in ander herrera s upload via instagram luke shaw angel di maria and michael carrick also trained in the week in what is undoubtedly a massive boost for manager louis van gaal video scroll down for sportsmail s premier league preview arsenal vs manchester united ander herrera right uploaded the above image via instagram with his manchester united team mates david de gea left and angel di maria pose for a selfie ahead of their clash against arsenal radamel falcao right has endured a difficult start to his career in a manchester united shirt angel di maria celebrates scoring for manchester united in their match against leicester city but united s midfield will be missing daley blind and marcos rojo is still out of the defence as he recovers from a shoulder injury arguably the most frustrating absentee is radamel falcao who has picked up another injury after struggling initially with a calf issue the players looked relaxed enough traveling with their laptop bottles of water and forbes magazine which features stories on finance industry investing and marketing topics forbes is also particularly known for its lists including revealing who the richest americans are in the world united are seventh in the premier league table but a victory at the emirates on saturday would see them overtake arsene wenger s side click to like our manchester united facebook page\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> ander herrera poses with juan mata angel di maria and david de gea manchester united could close the gap on the top four with victory but louis van gaal has a host of injuries to contend with for the game <END>\n",
      "Article =  cnn in a message to the iranian people an upbeat president barack obama said thursday that the long isolated middle east nation can soon improve its economy its world standing and its people s lives if there is a breakthrough nuclear deal for the first time in many years we have the opportunity to start down a new path obama said in a message timed for nowruz the persian new year a lot has changed since the last nowruz for one iranians elected hassan rouhani who campaigned in part on opening up iran more to the world including negotiations on its nuclear program as president last summer significant changes in tehran s approach followed leading to an interim agreement in november involving iran and the so called p5 1 the united states china russia britain france and germany the deal called for iran to roll back parts of its nuclear program in return for relief from some sanctions that agreement went into effect in january the challenge now is to reach a permanent deal acceptable to all sides obama said thursday that a comprehensive agreement this year can help open up new possibilities and prosperity for the iranian people for years to come that includes more open trade more jobs and more opportunities for iranian students according to the president noting the progress that has been made obama stressed that this will be difficult at the same time he insisted the united states is ready to talk i am committed to diplomacy the president said because i believe there is the basis for a practical solution\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> obama says he is committed to diplomacy with iran he says a comprehensive deal will open up opportunities prosperity for iran iran has been isolated internationally over its nuclear program an interim deal was reached last fall talks are under way for a bigger agreement <END>\n",
      "Article =  los angeles cnn katy perry is the most rewarded digital act ever according to the organization that hands out gold and platinum records perry fans have bought 72 million singles online which is 20 million more digital singles than the no 2 artist rihanna has sold the recording industry association of america announced taylor swift is third with 51 million digital singles sold how itunes changed music and the world the music industry group which started honoring vinyl record sales in 1958 launched its digital sales awards in 2004 when online music downloads not including the pirated versions became a mainstream way of buying songs the riaa added online music streaming to its tracking last year katy perry is the most followed on twitter perry has earned 18 gold 16 platinum and 56 multiplatinum digital singles awards in addition to her multiplatinum awards for her album teenage dream and a platinum award for the album one of the boys perry s top hits include i kissed a girl hot n cold dark horse and birthday riaa chairman cary sherman at a ceremony wednesday called perry a force to be reckoned with in music she embodies all that makes a true global superstar the musical talent the extraordinary drive and genuine charisma and an intrinsic connection with her fans sherman said the award is a reflection of her deep commitment to those qualities and to her music which has propelled her to this historic milestone katy perry disses miley s tongue miley bites back\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> her fans have bought 72 million digital singles online she has 18 gold 16 platinum and 56 multiplatinum digital singles awards recording industry association of america began awarding gold and platinum digital singles in 04 <END>\n",
      "Article =  cnn an oil tanker bound for the united states was hijacked off somalia with a crew of 28 aboard maritime authorities said the m v maran centaurus was commandeered about 600 nautical miles northeast of the seychelles on its way to new orleans louisiana according to the maritime security center the crew consists of 16 filipinos nine greeks two ukrainians and a romanian said the security agency which is run by the european naval force the 300 000 ton tanker which started out from jeddah saudi arabia was seized sunday it had changed course westward toward harardhere or hobyo along somali s central western coast somali pirates have turned high seas kidnappings into a lucrative business pirates have captured more than 50 ships this year off somalia and are currently holding 12 including the fishing vessel alakrana spanish defense minister carme chacon said recently attacks in the region have significantly increased this year according to the international maritime bureau which monitors shipping crimes but successful attacks have gone down as a result of a strong presence of international monitors the first nine months of this year have seen more pirate attacks than all of last year the bureau reported on october 21 from january 1 through september 30 pirates worldwide mounted 306 attacks compared with 293 in all of 2008 it said more than half of this year s attacks were carried out by suspected somali pirates off the east coast of somalia and in the gulf of aden a major shipping route between yemen and somalia\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> m v maran centaurus commandeered about 600 nautical miles northeast of the seychelles 300 000 ton tanker which started out from jeddah saudi arabia was seized sunday the crew consists of 16 filipinos nine greeks two ukrainians and a romanian <END>\n",
      "Article =  cnn in the hi tech era of electronic voting election authorities in the philippines settled a dead heat between two candidates for mayor in a decidedly old school way by flipping a coin when all the ballots were counted after monday s election the two men running for mayor in the town of san teodoro marvic feraren and boyet py both ended up with 3 236 votes each cnn affiliate abs cbn reported wednesday to break the impasse a decision was taken to use a coin reny pagilagan the town s acting election officer told the local broadcaster the philippine commission on elections permits coin flips as a way of deciding tied votes according to abs cbn so the two rivals faced off inside a ring of desks in a bare walled room taking it in turns to flick the coin to the ground at the end of the contest feraren the son of a previous mayor was declared the winner the outcome was received without negative reaction in san teodoro which is in the province of oriental mindoro abs cbn reported gunmen ambush mayor kill 10 supporters in the philippines\n",
      "\n",
      " Predicted Summary =  baby cnn have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple his couple have his couple his couple have his couple have his couple have his couple his his couple have his couple have his couple have his couple have his couple have his couple have his couple his couple have his couple have his couple have his couple have his couple have his couple his couple\n",
      "\n",
      " Reference Summary = <START> two candidates for mayor of san teodoro were tied on 3 236 votes each they settled the election by flipping a coin which is permitted by the election body the son of a previous mayor won the contest <END>\n",
      "Article =  by zoe szathmary a golf caddie for michael jordan was killed after he was hit by an allegedly drunk driver on friday neil fyfe 29 was hit by a jeep as he rode his bicycle across a southampton road the new york daily news reports and was pronounced dead at a nearby hospital jeep driver jesse werner steudte 21 was arrested by southampton police who they said was driving intoxicated bbc says victim neil fyfe pictured died on friday after he was killed by an allegedly drunk driver driver jesse steudte pictured was allegedly drunk at the time of the crash though his lawyer claims it may have been caused by a seizure steudte who is currently held on 25 000 cash bail admitted to drinking before the crash according to the new york post he pleaded not guilty to driving under the influence sources tell the paper fyfe was due to marry his fiancee jen in october and had previously caddied for luke donald and michael johnson the latter at famed the bear s club in jupiter florida michael jordan loves neil he is going to be very upset caddie frank weatherwax told the post a seizure may have caused the deadly crash steudte s lawyer colin astarita told 27 east astarita told the site steudte was unable to attend school this semester because of medication for a recent epilepsy diagnosis legend fyfe reportedly caddied for michael jordan pictured at the bear s club in florida\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> neil fyfe 29 was hit by a jeep as he rode his bicycle across a southampton road on friday night jeep driver jesse steudte 21 was arrested by southampton police who they said was driving intoxicated fyfe was due to marry his fiance in october and reportedly caddied for michael jordan <END>\n",
      "Article =  wales will have far more players fit and fresh to start six nations training next week compared with first opponents england whose leading men are involved in fierce club combat this weekend warren gatland the wales head coach would have viewed the raft of team announcements for the final round of european champions cup pool games with a sense of satisfaction several regular starters will be out of the line of fire which is not a luxury stuart lancaster has of the 15 likely to be picked to start for wales at the millennium stadium on february 6 seven are not in action including first choice half backs rhys webb and dan biggar of the ospreys england head coach stuart lancaster will be hoping to avoid any fresh injuries to his players this weekend england full back mike brown will be in action for harlequins against castres on saturday wales head coach warren gatland will be able to call on fresher players ahead of six nations opener alex cuthbert gethin jenkins sam warburton and toby faletau meanwhile are in challenge cup action rather than the elite event in contrast 13 of lancaster s likely xv will start champions cup ties with qualification at stake bath lock dave attwood has been named as a replacement but fly half george ford will start only gloucester wing jonny may who was rested from thursday night s win at brive will have had the benefit of a weekend of rest and recuperation the england coaches must hope to avoid any further injury setbacks before their training camp begins in surrey on monday given they are already without manu tuilagi ben morgan courtney lawes and joe launchbury\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> six nations training begins next week ahead of england s clash with wales thirteen of england s likely xi are in champions cup action this weekend however seven of wales likely xi are out of the firing line england coaches will be hoping to avoid any further injury setbacks <END>\n",
      "Article =  a louisiana teenager was killed while playing a game with friends on train tracks this weekend when some equipment threw him under one of the cars brandt torres 17 and three friends had been placing coins on train tracks to watch them be crushed early sunday law enforcement officials told the advocate his death comes just two years after torres almost died in a hunting accident brandt torres pictured after his 2012 hunting accident was tragically killed on louisiana train tracks torres lay on the ground inches from the passing cars as a ladder hanging off one of the cars caught him tossing him under the train he was just south of a union pacific rail yard in livonia and he died about 1 30 a m authorities say torres nearly died two years earlier in a hunting accident when he stood up in the path of a fellow duck hunter a sheriff s spokesman steve juge called his recovery close to a miracle he was critically injured to the point that they did not know if he would make it juge said the fatal train tracks incident is being investigated by union pacific as part of standard policies and the other teenagers will be interviewed brandt torres pictured left is pictured with his uncle last year\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> brandt torres 17 died on the train tracks in louisiana while playing with friends he nearly died two years ago when he stood up in the path of a fellow duck hunter <END>\n",
      "Article =  cnn after a long lockout the national basketball association will open its doors thursday for teams to hold voluntary workouts the move comes after last week s announcement that the players and owners had reached a tentative deal to end the league s months long lockout the season that was scheduled to have begun november 1 will now start christmas day team owners locked out players in early july as the two sides tried to hammer out a new agreement the sometimes bitter battle lasted 149 days one of the main sticking points was a split in revenues that owners said was unfair they sought to change the old revenue sharing arrangement that gave players 57 of the revenue the new deal offers a virtual 50 50 split training camps will open december 9 and the season will be 66 games instead of the usual 82 a previous lockout in the nba lasted 204 days from july 1998 to january 1999 before a new collective bargaining agreement was reached by both sides cnn s dan moriarty contributed to this report\n",
      "\n",
      " Predicted Summary =  baby cnn have his couple have his couple have his couple have his couple have his couple have his couple have his couple have his couple his couple have his couple have his couple have his couple have his couple his couple have his couple have his couple have his couple have his couple <END>\n",
      "\n",
      " Reference Summary = <START> this move comes after players and owners said they reached a deal the season will be 66 games instead of the usual 82 the deal gives players and owners a virtual 50 50 split of revenue nba com says <END>\n",
      "Article =  ew com there was a chance that two fewer emmys would be handed out during the telecast this year until now on thursday the academy of television arts sciences board of governors reversed its decision to consolidate the outstanding lead and supporting categories for actors and actresses in movies and miniseries last year the board in hopes of streamlining the annual telecast and making it well less boring voted to reduce the total number of categories by eliminating two of the telefilm actor categories but production of movies and miniseries has since increased hi the bible so the board reversed its decision so this year there will be four categories for outstanding lead actor and actress and supporting actor and actresses dexter season 8 officially its last reducing the number of categories during the three hour telecast has long been the goal of the big four networks which pay for the privilege of broadcasting the kudofest even though many of the golden statues go to premium and basic cable recipients each year the miniseries categories in particular have been dominated by cable actors the entry deadline for the 2013 primetime emmy awards is friday may nominations will be announced on july 18 for the telecast that will air on cbs sept 22 see the original article at ew com click here to try 2 risk free issues of entertainment weekly 2011 entertainment weekly and time inc all rights reserved\n",
      "\n",
      " Predicted Summary =  baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby\n",
      "\n",
      " Reference Summary = <START> it was originally decided that two emmy telefilm actor categories would be eliminated the academy of television arts sciences board of governors has reversed its decision this year there will be four categories for outstanding lead actor actress and supporting actor actresses <END>\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(rnn_encoder, rnn_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateForRouge(encoder, decoder, n=10):\n",
    "    preds = []\n",
    "    references = []\n",
    "    for i in tqdm(range(len(pairs_test))):\n",
    "        pair = pairs_test[i]\n",
    "        pair1 = torch.tensor(pair[0],dtype=torch.long,device=device)\n",
    "        pair2 = pair[1]\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair1)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        output_list = [ind2Word_dec[word] for word in pair2]\n",
    "        output_list = ' '.join(output_list)\n",
    "        preds.append(output_sentence)\n",
    "        references.append(output_list)\n",
    "    return preds, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.7.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.19.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2022.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.5.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.15.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "import evaluate as hf_evaluate\n",
    "\n",
    "rouge_score = hf_evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data['article']\n",
    "y_test = test_data['highlights']\n",
    "\n",
    "cleaned_source_test = list(map(clean,x_test))\n",
    "cleaned_summary_test = list(map(clean,y_test))\n",
    "\n",
    "for i in range(len(cleaned_summary_test)):\n",
    "    cleaned_summary_test[i] = START_TOKEN + \" \" + cleaned_summary_test[i] + \" \" + END_TOKEN\n",
    "\n",
    "max_source_length = 300\n",
    "max_summary_length = 100\n",
    "    \n",
    "new_source_test = []\n",
    "new_summary_test = []\n",
    "\n",
    "for i in range(len(cleaned_source_test)):\n",
    "    if len(cleaned_source_test[i].split()) <= max_source_length and len(cleaned_summary_test[i].split()) <= max_summary_length :\n",
    "        new_source_test.append(cleaned_source_test[i])\n",
    "        new_summary_test.append(cleaned_summary_test[i])\n",
    "    \n",
    "encoder_input_test = [[word2Index_enc[word] for word in sentence.split() if word in word2Index_enc.keys()] for sentence in new_source_test ]\n",
    "decoder_input_test = [[word2Index_dec[word] for word in sentence.split() if word in word2Index_dec.keys()] for sentence in new_summary_test ]\n",
    "    \n",
    "\n",
    "pairs_test = []\n",
    "for enc,dec in zip(encoder_input_test,decoder_input_test):\n",
    "    pairs_test.append([enc,dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1129/1129 [03:20<00:00,  5.64it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, references = evaluateForRouge(rnn_encoder, rnn_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 14.21, 'rouge2': 0.65, 'rougeL': 12.9, 'rougeLsum': 12.91}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge_score.compute(\n",
    "    predictions=preds, references=references\n",
    ")\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(scores[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pgen_Pointer_Generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
